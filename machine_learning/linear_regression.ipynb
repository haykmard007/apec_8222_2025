{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Linear Regression\n",
                "\n",
                "This notebook will introduce you to one of the most-used machine learning packages: sklearn. We will start easy with an example very familiar to us all: OLS.\n",
                "\n",
                "As always, start with our packages to import. The new one will be sklearn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import packages\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from sklearn import datasets, linear_model\n",
                "from sklearn.metrics import mean_squared_error, r2_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the imports above, we imported sub-packages of the sklearn package. Rather than loading the whole sklearn library (which is huge), line 4 just imports datasets and linear_model.\n",
                "\n",
                "### Load a specific dataset\n",
                "\n",
                "Next, we will use the imported datasets object. It defines a useful function load_diabetes(). This will return a dataset object which contains the data and metadata."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "full_dataset {'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
                        "         0.01990749, -0.01764613],\n",
                        "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
                        "        -0.06833155, -0.09220405],\n",
                        "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
                        "         0.00286131, -0.02593034],\n",
                        "       ...,\n",
                        "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
                        "        -0.04688253,  0.01549073],\n",
                        "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
                        "         0.04452873, -0.02593034],\n",
                        "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
                        "        -0.00422151,  0.00306441]], shape=(442, 10)), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
                        "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
                        "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
                        "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
                        "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
                        "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
                        "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
                        "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
                        "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
                        "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
                        "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
                        "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
                        "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
                        "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
                        "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
                        "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
                        "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
                        "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
                        "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
                        "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
                        "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
                        "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
                        "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
                        "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
                        "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
                        "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
                        "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
                        "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
                        "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
                        "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
                        "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
                        "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
                        "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
                        "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
                        "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
                        "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
                        "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
                        "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
                        "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
                        "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
                        "       220.,  57.]), 'frame': None, 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'diabetes_data_raw.csv.gz', 'target_filename': 'diabetes_target.csv.gz', 'data_module': 'sklearn.datasets.data'}\n"
                    ]
                }
            ],
            "source": [
                "# Here we will load the diabetes dataset, which is a built-in dataset from sklearn.\n",
                "full_dataset = datasets.load_diabetes()\n",
                "print('full_dataset', full_dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Inspect the dataset object to learn about it\n",
                "\n",
                "It's overwhelming and hard to read what is printed out, but let's dig into this notation because it's frequently used and will help us understand different Python datatypes.\n",
                "\n",
                "First, notice that the object starts with {, which means we can treat it like a python dicitonary. Dictionaries are standard ways of expressing key-value pairs. The standard notation for a dictionary is {key1: value1, key2: value2}\n",
                "\n",
                "Below, we will use a method from the full_dataset object that returns just the keys. This should be easier to parse."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "dictionary keys: dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n"
                    ]
                }
            ],
            "source": [
                "print('dictionary keys:', full_dataset.keys())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we want, we can access just one entry in the dictionary using the key. A useful one is the key DESCR.\n",
                "\n",
                "Print that out using the dictionary \\[\\] notation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ".. _diabetes_dataset:\n",
                        "\n",
                        "Diabetes dataset\n",
                        "----------------\n",
                        "\n",
                        "Ten baseline variables, age, sex, body mass index, average blood\n",
                        "pressure, and six blood serum measurements were obtained for each of n =\n",
                        "442 diabetes patients, as well as the response of interest, a\n",
                        "quantitative measure of disease progression one year after baseline.\n",
                        "\n",
                        "**Data Set Characteristics:**\n",
                        "\n",
                        ":Number of Instances: 442\n",
                        "\n",
                        ":Number of Attributes: First 10 columns are numeric predictive values\n",
                        "\n",
                        ":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
                        "\n",
                        ":Attribute Information:\n",
                        "    - age     age in years\n",
                        "    - sex\n",
                        "    - bmi     body mass index\n",
                        "    - bp      average blood pressure\n",
                        "    - s1      tc, total serum cholesterol\n",
                        "    - s2      ldl, low-density lipoproteins\n",
                        "    - s3      hdl, high-density lipoproteins\n",
                        "    - s4      tch, total cholesterol / HDL\n",
                        "    - s5      ltg, possibly log of serum triglycerides level\n",
                        "    - s6      glu, blood sugar level\n",
                        "\n",
                        "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
                        "\n",
                        "Source URL:\n",
                        "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
                        "\n",
                        "For more information see:\n",
                        "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
                        "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(full_dataset['DESCR'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Access the data array\n",
                "\n",
                "Use the `'data'` key could also extract the data and assign it to a data_array variable for inspection. Let's also print out the `type` of the object to see what the data format is."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data_array [[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990749\n",
                        "  -0.01764613]\n",
                        " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06833155\n",
                        "  -0.09220405]\n",
                        " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286131\n",
                        "  -0.02593034]\n",
                        " ...\n",
                        " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04688253\n",
                        "   0.01549073]\n",
                        " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452873\n",
                        "  -0.02593034]\n",
                        " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00422151\n",
                        "   0.00306441]]\n",
                        "<class 'numpy.ndarray'>\n"
                    ]
                }
            ],
            "source": [
                "data_array = full_dataset['data']\n",
                "print('data_array', data_array)\n",
                "print(type(data_array))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It's a numpy array! That means we can use any of the numpy array functions on it.\n",
                "\n",
                "## Exercise 1:\n",
                "\n",
                "Print out the mean BMI in the dataset, the sum BMI, and the sum of the squared BMI values. Explain why the sum of the squared BMI is what it is. To do this, you will need to access the right parts of the data array and slice out the right column.\n",
                "\n",
                "HINT: You will need to read the DESCR to understand which column the BMI is stored in.\n",
                "\n",
                "HINT 2: To create a new variable with just the desired column of the array, you can use Array slicing notation like a = data_array\\[:, n\\] where the : means you want ALL rows, and the n means you want just column n.\n",
                "\n",
                "HINT 3: You may want to use data_array.sum(), data_array.mean(), and the \\*\\* exponent operator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sum:  -9.9253938401489e-14\n",
                        "Mean:  -2.2455642172282577e-16\n",
                        "Sum of squared:  0.0022624434389140265\n"
                    ]
                }
            ],
            "source": [
                "bmi = data_array[:, 2]\n",
                "\n",
                "bmi_squared = bmi ** 2\n",
                "\n",
                "print('Sum: ', bmi.sum())\n",
                "print('Mean: ', bmi.mean())\n",
                "print('Sum of squared: ', bmi_squared.mean())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For conveinence, sklearn also just has an option to get the key parts for the regression ready to use.\n",
                "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "diabetes_X (442, 10)\n",
                        "diabetes_y (442,)\n"
                    ]
                }
            ],
            "source": [
                "# Look at diabetes_X and notice there are lots of independent variables. Rather than printing the whole\n",
                "# Array, which would be messy, just look at the .shape attribute.l\n",
                "# print('diabetes_X', diabetes_X)\n",
                "print('diabetes_X', diabetes_X.shape)\n",
                "print('diabetes_y', diabetes_y.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For now, we're just going to use a single variable (a single column) for simplicity. The following line extracts just the second column from the array. The colon was necessary because we access arrays using the ROW, COLUMN notation, so we sliced out all ROWS (the colon indicates all) and the second COLUMN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "diabetes_X (442,)\n",
                        "diabetes_X (442, 1)\n"
                    ]
                }
            ],
            "source": [
                "diabetes_X = diabetes_X[:, 2]\n",
                "# diabetes_X = np.array([diabetes_X])\n",
                "# diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
                "# print('diabetes_X', diabetes_X)\n",
                "print('diabetes_X', diabetes_X.shape)\n",
                "\n",
                "# diabetes_X = diabetes_X.reshape((:, 1))\n",
                "diabetes_X = diabetes_X.reshape((diabetes_X.shape[0], 1))\n",
                "\n",
                "# print('diabetes_X', diabetes_X)\n",
                "print('diabetes_X', diabetes_X.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Split into training and testing arrays (the manual way)\n",
                "\n",
                "Next we are going to do a very rudimentary split of the data into training and testing sets using array slice notation. The following lines assigns the last all but the last 20 lines to the TRAIN set and the remaining 20 to the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabetes_X_train = diabetes_X[:-20]\n",
                "diabetes_X_test = diabetes_X[-20:]\n",
                "diabetes_y_train = diabetes_y[:-20]\n",
                "diabetes_y_test = diabetes_y[-20:]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Create an empty LinearRegression object.**\n",
                "\n",
                "In the lines below, we will follow a relatively standardized process for running a model:\n",
                "\n",
                "1.  Create the model object.\n",
                "2.  Fit the model.\n",
                "3.  Predict with the model\n",
                "\n",
                "The basic notation for sklearn below first creates a regression model object using the `linear_model` that we imported above. This model is \"empty\" in the sense that it has no coefficients identified. Just like othertimes we've encountered objects (like numpy array objects), this object has many functions (called methods) and attributes which can be accessed by the dot operator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "regression_object LinearRegression()\n"
                    ]
                }
            ],
            "source": [
                "regression_object = linear_model.LinearRegression()\n",
                "print('regression_object', regression_object)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Use the fit method\n",
                "\n",
                "Use the fit method from our regression object. It takes two inputs, the independent variables (X) and dependent variables (y).\n",
                "\n",
                "Below, we will ONLY use the training subset of the data we created above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LinearRegression()\n"
                    ]
                }
            ],
            "source": [
                "regression_object.fit(diabetes_X_train, diabetes_y_train)\n",
                "print(regression_object)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Use the fitted model to predict values\n",
                "\n",
                "Now the regression_object is \"trained,\" which means we can also call it's predict() method which will take some other observations and (in the case of OLS), multiple the new observations against our trained coefficients to make a prediciton.\n",
                "\n",
                "The predict method returned an array of numerical predictions, which we will look at."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[225.9732401  115.74763374 163.27610621 114.73638965 120.80385422\n",
                        " 158.21988574 236.08568105 121.81509832  99.56772822 123.83758651\n",
                        " 204.73711411  96.53399594 154.17490936 130.91629517  83.3878227\n",
                        " 171.36605897 137.99500384 137.99500384 189.56845268  84.3990668 ]\n"
                    ]
                }
            ],
            "source": [
                "diabetes_y_pred = regression_object.predict(diabetes_X_test)\n",
                "print(diabetes_y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Look at the coefficients\n",
                "\n",
                "More interesting might be to look at the coefficients. Once the model has been fit, it has a new attribute .coef\\_ which stores an array of coefficients. In this case it will only be an array of length 1 because we just have one input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Coefficients: \n",
                        " [938.23786125]\n"
                    ]
                }
            ],
            "source": [
                "print('Coefficients: \\n', regression_object.coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You might be wondering why we are looking at the coefficients as a raw array rather than at a nicely formatted regression table. The reason is in cross-validation approaches, these coefficients might just be one step towards the final model performance check on unseen data.\n",
                "\n",
                "#### Evaluating the fit\n",
                "\n",
                "We can use sklearn's built in evaluation functions, such as for the mean squared error or other metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mean squared error on the TEST data: 2548.0723987259694\n"
                    ]
                }
            ],
            "source": [
                "mse = mean_squared_error(diabetes_y_test, diabetes_y_pred)\n",
                "print('Mean squared error on the TEST data:',  mse)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "r2 calculated on TEST data:  0.47257544798227147\n"
                    ]
                }
            ],
            "source": [
                "# Or perhaps we want the r2 for the second independent variable (which is the only one we used)\n",
                "r2_score_value = r2_score(diabetes_y_test, diabetes_y_pred)\n",
                "print('r2 calculated on TEST data: ', r2_score_value)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Finally, to prove to ourselves that we know what we are doing, let's plot this.\n",
                "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
                "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 2.1: Machine Learning OLS Mashup.\n",
                "\n",
                "Use loops to find which TWO variables best describe the data, as measured by R-squared. This is a hilariously brute-force approach to OLS model selection, but it is similar in some senses to Machine Learning and will be relevant to the cross-validation approaches we discuss next."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "best_option [0, 0, 0.47257544798227147]\n"
                    ]
                }
            ],
            "source": [
                "# Exercise 2.1 workspace and starter code\n",
                "\n",
                "\n",
                "full_dataset = datasets.load_diabetes() # Load the full dataset\n",
                "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True) # Get just the data arrays\n",
                "\n",
                "# Split into training and testing\n",
                "diabetes_X_train = diabetes_X[:-20]\n",
                "diabetes_X_test = diabetes_X[-20:]\n",
                "diabetes_y_train = diabetes_y[:-20]\n",
                "diabetes_y_test = diabetes_y[-20:]\n",
                "\n",
                "highest_score = 0\n",
                "for i in range(len(full_dataset['feature_names'])):\n",
                "    for j in range(len(full_dataset['feature_names'])):\n",
                "        \n",
                "        diabetes_current_X_train = diabetes_X_train[:, [i, j]]\n",
                "        diabetes_current_X_test = diabetes_X_test[:, [i, j]]\n",
                "\n",
                "        # MISSING STUFF HERE.       \n",
                "        \n",
                "        if r2_score_value > highest_score:\n",
                "            highest_score = r2_score_value\n",
                "            best_option = [i, j, r2_score_value]\n",
                "        \n",
                "print('best_option', best_option)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Just for completeness, let's look at this the way an econometritian would\n",
                "\n",
                "Sklearn doesn't report summary statistics in the classic, econometric sense because it focuses on the train, test paradigm, which is not equivilent to a model performance report (which in the classic case is only reporting performance of the TRAINING data).\n",
                "\n",
                "Nonetheless, Here's how I do it, using an alternative, more econometrics-focused package. You will need to conda install statsmodel if you want to uncomment this line and have it work. Note that because we're not splitting our data into training and testing, the r-squareds are not really comparable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                            OLS Regression Results                            \n",
                        "==============================================================================\n",
                        "Dep. Variable:                      y   R-squared:                       0.518\n",
                        "Model:                            OLS   Adj. R-squared:                  0.507\n",
                        "Method:                 Least Squares   F-statistic:                     46.27\n",
                        "Date:                Tue, 11 Nov 2025   Prob (F-statistic):           3.83e-62\n",
                        "Time:                        12:49:52   Log-Likelihood:                -2386.0\n",
                        "No. Observations:                 442   AIC:                             4794.\n",
                        "Df Residuals:                     431   BIC:                             4839.\n",
                        "Df Model:                          10                                         \n",
                        "Covariance Type:            nonrobust                                         \n",
                        "==============================================================================\n",
                        "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "const        152.1335      2.576     59.061      0.000     147.071     157.196\n",
                        "x1           -10.0099     59.749     -0.168      0.867    -127.446     107.426\n",
                        "x2          -239.8156     61.222     -3.917      0.000    -360.147    -119.484\n",
                        "x3           519.8459     66.533      7.813      0.000     389.076     650.616\n",
                        "x4           324.3846     65.422      4.958      0.000     195.799     452.970\n",
                        "x5          -792.1756    416.680     -1.901      0.058   -1611.153      26.802\n",
                        "x6           476.7390    339.030      1.406      0.160    -189.620    1143.098\n",
                        "x7           101.0433    212.531      0.475      0.635    -316.684     518.770\n",
                        "x8           177.0632    161.476      1.097      0.273    -140.315     494.441\n",
                        "x9           751.2737    171.900      4.370      0.000     413.407    1089.140\n",
                        "x10           67.6267     65.984      1.025      0.306     -62.064     197.318\n",
                        "==============================================================================\n",
                        "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
                        "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
                        "Skew:                           0.017   Prob(JB):                        0.496\n",
                        "Kurtosis:                       2.726   Cond. No.                         227.\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
                    ]
                }
            ],
            "source": [
                "import statsmodels\n",
                "from statsmodels.api import OLS\n",
                "\n",
                "data_with_constant = statsmodels.api.add_constant(full_dataset.data)\n",
                "result = OLS(full_dataset.target, data_with_constant).fit().summary()\n",
                "print(result)"
            ]
        }
    ],
    "metadata": [
        {
            "kernelspec": {
                "display_name": "Python 3 (ipykernel)",
                "language": "python",
                "name": "python3"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 4
}
